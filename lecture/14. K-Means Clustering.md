### 14-1. clustering
- clustering: unlabeled data points가 주어졌을 때, data cloud를 K개 prototype vector로 표현한다. (cluster center)
	- 이러한 prototype vector에 의해 전체 영역이 partitioned되어야 함.
- 목적은 각 데이터포인트와 그 포인트가 속한 군집의 중심 사이의 거리가 최소화되어야 한다. 이러한 거리를 $J(\mu,z)=\sum_i ||x^{(i)}-\mu_{z^{(i)}}||^2$이라고 쓰고 distortion 혹은 SSE라고 부른다.
	- 이를 한번에 찾는건 NP-hard이고, 정답을 한번에 맞추기 어려운 non-convex problem임.
- 알고리즘
	- assignment step: 중심점 $\mu$가 고정되어 있을 때, 최적의 할당 $z$를 찾기.
		- 단순하게 그냥 가장 가까운 걸 선택한다.
		- 수학적으로는 보로노이 다이어그램 형태로 분할하는 것임.
	- center update step: 할당 $z$가 고정되어 있을 때, 중심점 $\mu$를 수정하기
		- 각 군집에 속한 데이터의 평균값을 구한다.
		- $J$를 $\mu_k$에 대해 편미분해서 0이 되는지점을 찾으면 데이터 포인트의 산술 평균이 나온다.
	- 위 과정은 중심점이 더 이상 변하지 않을 때까지 반복된다.
### 14-2. optimization perspective
- k-mean은 수학적으로 block coordinate descent의 한 종류이다.
	- 복잡한 함수를 최적화할 때, 변수의 묶음을 나누어 번갈아 가면서 최적화하는 방식
	- 블록이 2개임. $z$ 블록과 $\mu$ 블록
- convergence guarantee
	- k-mean은 각 단계가 목적 함수를 단조 감소하게 한다.
	- 목적 함수는 0 이상이며, 가능한 할당의 가짓수가 $K^N$개로 유한하다.
	- 매 단계 $J$가 줄어든다면 이미 거쳐온 할당으로 돌아가지는 않는다.
	- 따라서, 반드시 수렴한다.
- 알고리즘이 항상 global sol을 찾지는 않는다.
- k-mean은 데이터를 가장 가까운 중심점($x^{(i)} \approx \mu_{z^{(i)}}$)으로 대체하는 손실 압축 과정으로도 해석할 수 있다.
### 14-3. evaluation
- silhouette analysis
	- $a(i)$: 같은 군집 내의 데이터 평균 거리
	- $b(i)$: 가장 가까운 이웃 군집 데이터와의 평균 거리
	- 각 점 $x^{(i)}$에 대해서, 실루엣 계수 $s(i)=\frac{b(i)-a(i)}{\max{a(i),b(i)}} \in [-1,1]$가 1에 가까울수록 잘 그룹화됨.
		- 음수면 잘못 할당된 것일 가능성이 높다.
- elbow method: 정답 레이블이 없을 때 grouping이 잘 되었는지 확인하는 방법
	- group의 수 K를 늘려가면서 J를 그래프로 그린다.
	- K가 커질수록 J는 당연히 줄어든다.
	- 감소 폭이 급격하게 줄어드는 elbow 지점이 최적의 K이다.
### 14-4. consideration
- 실무에선 K-mean++ 같이 초기화 방법을 개선해서 사용하거나, 여러 번 돌려서 가장 잘 만든 것을 사용.
- 유클리드 거리를 쓰기 때문에, 데이터의 스케일에 민감하다. 따라서, 표준화를 해줘야 한다.
- 군집이 구형이고, 크기가 비슷하며, 잘 분리되어 있다고 가정한다. 길쭉한 군집에는 적절하지 않다.
- 극단값이 평균을 끌어당겨 군집 중심이 왜곡될 수 있다.
