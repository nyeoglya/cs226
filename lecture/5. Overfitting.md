### Goals
- Overfitting
- Generalization Theorem
### 5-1. Learning Setup and Notation
- Instance space: $X$
- Label space: $Y$
- instance-label pairs(data) $(x,y) \sim D$를 뽑는다. 이러한 집합을 $S$라 하자. 여기서 $D$는 unknown distribution.
	- 이 pair들은 나중에 training set으로 사용된다.
- a set of all classifiers: $H$ ← ㅈㄴ 큰 집합
- find the alg. chooses the "best" classifier from $H$.
	- 100개의 뉴런이 4바이트를 차지한다면, 3200bit이다. 그러면 가능한 classifier는 $2^{3200}$
- 이제부터 여기서는 binary classifier만 생각하자. $h\in H$에 대해, $x\in X\to \{-1,1\}\in Y$.
- training error(empirical risk): $\hat{R}_S(h)=\frac{1}{m}\sum\mathbb{1}\{h(x_i)\neq y\}$
- true error(generalization error, expected risk): $R(h)=P_{(x,y)\sim D}[h(x)\neq y]=E_{(x,y)\sim D}[\mathbb{1}\{h(x)\neq y\}]$
	- 베르누이 분포임...??
- ideal하게는 $\text{argmin}_{h\in H}{R}(h)$를 찾는거지만 그건 불가능하기 때문에, 현실적으로는 $\text{argmin}_{h\in H}\hat{R}_S(h)$를 찾는걸 최종 목적으로 한다.
### 5-2. Decision Trees: Greedy Splitting & Local Sample Sizes
- decision tree에서 하나의 node $\mu$에 대해, $S(\mu)\subseteq S$: subset that has reached node $\mu$ after all preceding splits. 라 하자.
	- node를 타고 내려갈수록 이러한 $|S(\mu)|$는 점점 감소한다. (노드 수가 줄어들기 때문)
	- 노드가 줄어들수록 값 자체가 줄어들기 때문에 통계적인 신뢰성이 떨어진다. 이를 늘리기 위해서는 $S$가 엄청 커야 한다. 왜냐면 $|S(\mu)|$는 계속 감소하기 때문이다.
	- $P(Y|\mu)$: class proportion
- path가 깊어질수록 높은 variance를 갖는다. 데이터셋의 작은 변화에도 큰 영향을 받는다는 말이다. (별로 안 좋음)
	- $\hat{p}(y=1|x\in\text{leaf})$가 결정되면 나머지 1개는 바로 결정되기 때문에 하나만 관심을 갖는다.
- greedy search를 너무 많은 split에서 하면 spurious split(=noise-fitting split=fake split)을 늘린다.
### 5-3. Finite-Class Uniform Convergence Bound
**The Generalization Theorem.** With high probability (at least $1-\delta$), for all classifier $h \in H$,
$$
R(h)\le \hat{R}_S(h)+\sqrt{\frac{\ln(1/\delta)+\ln(|H|)}{2m}}
$$
where $m$ is the sample size.
- 여기서 $H|$는 decision tree의 node 수에 비례한다. 즉, 이건 줄여야 한다. (우리가 depth를 줄여야 하는 이유)
#### 5-3-1. Hoeffding and Union Bounds
**Hoeffding (Bernoulli).** Given a random variable $X_1,\cdots,X_n \sim Bern(p)$
$$
P\left[\frac{1}{m}\sum X_i-p>\alpha\right]\le e^{-2m\alpha^2}
$$
$$
P\left[p-\frac{1}{m}\sum X_i>\alpha\right]\le e^{-2m\alpha^2}
$$
where $\alpha$ is the error margin, and $p$ is the true mean.
- 즉, sample 개수가 늘어나면 exponentially하게 감소한다.
- 여기서 $\frac{1}{m}\sum X_i-p>\alpha$ 조건은 안좋은 케이스를 의미한다. (특정 error를 넘어선다는 뜻)
**Union bound.** For events $E_1,\cdots,E_n$,
$$
P\left[\bigcup_{i=1}^nE_i\right] \leq \sum P[E_i]
$$
#### 5-3-2. Proof of the Generalization Theorem
Fix $h \in H$. Define $X_i = \mathbb{1}\{h(x_i)\ne y_i\}$. Then, $\hat{R}_S(h)=\frac{1}{m}\sum X_i$. By i.i.d.(identical, independent) sampling,
$$
E[X_i]=P_{(x,y)\sim D}[h(x_i)\ne y]=R(h)
$$
We want to find $\alpha$ so,
$$
P[\hat{R}_S(h)<R(h)-\alpha]\le e^{-2m\alpha^2}=\frac{\delta}{|H|}
$$
So with high event, with at least $1-\delta/|H|$,
$$
R(h)\le \hat{R}_S(h)+\alpha
$$
(This is for a single classifier)
Note that the $\alpha$ is
$$
\alpha=\sqrt{\frac{\ln(1/\delta)+\ln|H|}{2m}}
$$
Now, define $E_h=\{\hat{R}_S(h)<R(h)-\alpha\}$. Since $P[E_h]\le \delta / |H|$. By the union bound,
$$
P\left[\bigcup_{h\in H}E_h\right] \leq \sum P[E_h]=\sum_{h\in H}\frac{\delta}{|H|}=\delta
$$
(이건 bad event를 모아둔 것이다. 이것이 bounded by $\delta$임을 보였다)
So with high probability, no event $E_h$ occurs for all classifiers.
$$
R(h)\le \hat{R}_S(h)+\alpha
$$
(This is for all classifiers)
#### 5-3-3.How the theorem Explains Overfitting
- small leaves → high variance. large hypothesis space $H$. 그러면 generalization gap $R-\hat{R}$이 증가한다.
- decisiontree에서 overfitting을 막는 3개의 방법이 있다.
	- pre-pruning: sample size가 일정 이하면 멈추거나, depth가 일정 이상이면 멈추게 한다.
	- post-pruning: tree를 다 구성하고 날리는 거임.
	- data: sample size $m$을 늘린다.
